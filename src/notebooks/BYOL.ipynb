{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Hx1knq7pDFy"
      },
      "source": [
        "## GitHub Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_MMqvU5pDF1",
        "outputId": "52c7ef6d-5663-422b-9b9e-da8e6b7e30fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'HITS-SDO-Independent-Research'...\n",
            "remote: Enumerating objects: 4575, done.\u001b[K\n",
            "remote: Counting objects: 100% (1158/1158), done.\u001b[K\n",
            "remote: Compressing objects: 100% (729/729), done.\u001b[K\n",
            "remote: Total 4575 (delta 412), reused 1104 (delta 382), pack-reused 3417\u001b[K\n",
            "Receiving objects: 100% (4575/4575), 37.86 MiB | 25.88 MiB/s, done.\n",
            "Resolving deltas: 100% (3779/3779), done.\n",
            "/content/HITS-SDO-Independent-Research\n",
            "Already on 'main'\n",
            "Your branch is up to date with 'origin/main'.\n"
          ]
        }
      ],
      "source": [
        "# Clone the repository from GitHub\n",
        "!git clone https://github.com/hits-sdo/HITS-SDO-Independent-Research.git\n",
        "%cd HITS-SDO-Independent-Research/\n",
        "!git checkout main"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNuU_jAgpDF3"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxyOJqzSpDF3",
        "outputId": "1ab2d7ba-e2cd-43b1-a14b-76ba16e4c5d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/5.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/5.2 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/5.2 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for hdbscan (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jhw_ocMqpDF4"
      },
      "outputs": [],
      "source": [
        "# Standard Libraries\n",
        "import copy\n",
        "import glob\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# NumPy\n",
        "import numpy as np\n",
        "\n",
        "# SciPy\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Matplotlib\n",
        "import PIL.Image as Image\n",
        "import matplotlib.offsetbox as offsetbox\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#HDBSCAN\n",
        "import hdbscan\n",
        "\n",
        "# Lightly\n",
        "from lightly.loss import NegativeCosineSimilarity, NTXentLoss\n",
        "from lightly.models.modules import BYOLPredictionHead, BYOLProjectionHead\n",
        "from lightly.models.utils import deactivate_requires_grad, update_momentum\n",
        "from lightly.utils.scheduler import cosine_schedule\n",
        "\n",
        "# Sklearn\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "\n",
        "# PyTorch\n",
        "import pytorch_lightning as pl\n",
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "# External files\n",
        "sys.path.append(os.path.abspath('./../../sdo_augmentation/'))\n",
        "from augmentation import Augmentations\n",
        "from augmentation_list import AugmentationList\n",
        "from augmentation_test import read_image\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zl0vwwPxpDF5"
      },
      "source": [
        "## Download and Unzip Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "859yM8-9pDF5",
        "outputId": "cc553cc2-9ada-4b87-d668-da15f1b2e9e6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From (uriginal): https://drive.google.com/uc?id=16WD0td1f5gx4yIIDkWWSTb-oZcezI1CU\n",
            "From (redirected): https://drive.google.com/uc?id=16WD0td1f5gx4yIIDkWWSTb-oZcezI1CU&confirm=t&uuid=f2ff4a9f-a761-456b-b93a-1b82a3737b63\n",
            "To: c:\\Github Repositories\\HITS-SDO-Independent-Research\\src\\notebooks\\AIA171_Miniset_BW.tar.gz\n",
            "\n",
            "  0%|          | 0.00/147M [00:00<?, ?B/s]\n",
            "  0%|          | 524k/147M [00:00<00:33, 4.40MB/s]\n",
            "  1%|▏         | 2.10M/147M [00:00<00:16, 8.76MB/s]\n",
            "  3%|▎         | 3.67M/147M [00:00<00:14, 10.1MB/s]\n",
            "  4%|▎         | 5.24M/147M [00:00<00:13, 10.6MB/s]\n",
            "  5%|▍         | 6.82M/147M [00:00<00:12, 11.0MB/s]\n",
            "  6%|▌         | 8.39M/147M [00:00<00:12, 11.2MB/s]\n",
            "  7%|▋         | 9.96M/147M [00:00<00:12, 11.3MB/s]\n",
            "  8%|▊         | 11.5M/147M [00:01<00:11, 11.4MB/s]\n",
            "  9%|▉         | 13.1M/147M [00:01<00:11, 11.4MB/s]\n",
            " 10%|█         | 14.7M/147M [00:01<00:11, 11.4MB/s]\n",
            " 11%|█         | 16.3M/147M [00:01<00:11, 11.5MB/s]\n",
            " 12%|█▏        | 17.8M/147M [00:01<00:11, 11.5MB/s]\n",
            " 13%|█▎        | 19.4M/147M [00:01<00:11, 11.5MB/s]\n",
            " 14%|█▍        | 21.0M/147M [00:01<00:10, 11.5MB/s]\n",
            " 15%|█▌        | 22.5M/147M [00:02<00:10, 11.5MB/s]\n",
            " 16%|█▋        | 24.1M/147M [00:02<00:10, 11.6MB/s]\n",
            " 18%|█▊        | 25.7M/147M [00:02<00:10, 11.5MB/s]\n",
            " 19%|█▊        | 27.3M/147M [00:02<00:10, 11.5MB/s]\n",
            " 20%|█▉        | 28.8M/147M [00:02<00:10, 11.5MB/s]\n",
            " 21%|██        | 30.4M/147M [00:02<00:10, 11.6MB/s]\n",
            " 22%|██▏       | 32.0M/147M [00:02<00:09, 11.5MB/s]\n",
            " 23%|██▎       | 33.6M/147M [00:02<00:09, 11.6MB/s]\n",
            " 24%|██▍       | 35.1M/147M [00:03<00:09, 11.5MB/s]\n",
            " 25%|██▌       | 36.7M/147M [00:03<00:09, 11.6MB/s]\n",
            " 26%|██▌       | 38.3M/147M [00:03<00:09, 11.5MB/s]\n",
            " 27%|██▋       | 39.8M/147M [00:03<00:09, 11.5MB/s]\n",
            " 28%|██▊       | 41.4M/147M [00:03<00:09, 11.5MB/s]\n",
            " 29%|██▉       | 43.0M/147M [00:03<00:08, 11.5MB/s]\n",
            " 30%|███       | 44.6M/147M [00:03<00:08, 11.6MB/s]\n",
            " 31%|███▏      | 46.1M/147M [00:04<00:08, 11.6MB/s]\n",
            " 33%|███▎      | 47.7M/147M [00:04<00:08, 11.6MB/s]\n",
            " 34%|███▎      | 49.3M/147M [00:04<00:08, 11.6MB/s]\n",
            " 35%|███▍      | 50.9M/147M [00:04<00:08, 11.6MB/s]\n",
            " 36%|███▌      | 52.4M/147M [00:04<00:08, 11.6MB/s]\n",
            " 37%|███▋      | 54.0M/147M [00:04<00:08, 11.6MB/s]\n",
            " 38%|███▊      | 55.6M/147M [00:04<00:07, 11.6MB/s]\n",
            " 39%|███▉      | 57.1M/147M [00:05<00:07, 11.6MB/s]\n",
            " 40%|████      | 58.7M/147M [00:05<00:07, 11.6MB/s]\n",
            " 41%|████      | 60.3M/147M [00:05<00:08, 10.5MB/s]\n",
            " 42%|████▏     | 61.9M/147M [00:05<00:09, 8.93MB/s]\n",
            " 43%|████▎     | 63.4M/147M [00:05<00:08, 9.59MB/s]\n",
            " 44%|████▍     | 65.0M/147M [00:05<00:08, 10.1MB/s]\n",
            " 45%|████▌     | 66.6M/147M [00:05<00:07, 10.5MB/s]\n",
            " 46%|████▋     | 68.2M/147M [00:06<00:07, 10.8MB/s]\n",
            " 48%|████▊     | 69.7M/147M [00:06<00:06, 11.0MB/s]\n",
            " 49%|████▊     | 71.3M/147M [00:06<00:06, 11.2MB/s]\n",
            " 50%|████▉     | 72.9M/147M [00:06<00:06, 11.3MB/s]\n",
            " 51%|█████     | 74.4M/147M [00:06<00:06, 11.3MB/s]\n",
            " 52%|█████▏    | 76.0M/147M [00:06<00:06, 11.4MB/s]\n",
            " 53%|█████▎    | 77.6M/147M [00:06<00:06, 11.4MB/s]\n",
            " 54%|█████▍    | 79.2M/147M [00:07<00:05, 11.5MB/s]\n",
            " 55%|█████▌    | 80.7M/147M [00:07<00:05, 11.5MB/s]\n",
            " 56%|█████▌    | 82.3M/147M [00:07<00:05, 11.5MB/s]\n",
            " 57%|█████▋    | 83.9M/147M [00:07<00:05, 11.5MB/s]\n",
            " 58%|█████▊    | 85.5M/147M [00:07<00:05, 11.5MB/s]\n",
            " 59%|█████▉    | 87.0M/147M [00:07<00:05, 11.6MB/s]\n",
            " 60%|██████    | 88.6M/147M [00:07<00:05, 11.5MB/s]\n",
            " 61%|██████▏   | 90.2M/147M [00:08<00:04, 11.5MB/s]\n",
            " 63%|██████▎   | 91.8M/147M [00:08<00:04, 11.6MB/s]\n",
            " 64%|██████▎   | 93.3M/147M [00:08<00:04, 11.5MB/s]\n",
            " 65%|██████▍   | 94.9M/147M [00:08<00:04, 11.5MB/s]\n",
            " 66%|██████▌   | 96.5M/147M [00:08<00:04, 11.5MB/s]\n",
            " 67%|██████▋   | 98.0M/147M [00:08<00:04, 11.6MB/s]\n",
            " 68%|██████▊   | 99.6M/147M [00:08<00:04, 11.5MB/s]\n",
            " 69%|██████▉   | 101M/147M [00:08<00:03, 11.5MB/s] \n",
            " 70%|███████   | 103M/147M [00:09<00:03, 11.5MB/s]\n",
            " 71%|███████   | 104M/147M [00:09<00:03, 11.5MB/s]\n",
            " 72%|███████▏  | 106M/147M [00:09<00:03, 11.6MB/s]\n",
            " 73%|███████▎  | 107M/147M [00:09<00:03, 11.6MB/s]\n",
            " 74%|███████▍  | 109M/147M [00:09<00:03, 11.5MB/s]\n",
            " 75%|███████▌  | 111M/147M [00:09<00:03, 11.6MB/s]\n",
            " 76%|███████▋  | 112M/147M [00:09<00:02, 11.5MB/s]\n",
            " 78%|███████▊  | 114M/147M [00:10<00:02, 11.5MB/s]\n",
            " 79%|███████▊  | 115M/147M [00:10<00:02, 11.6MB/s]\n",
            " 80%|███████▉  | 117M/147M [00:10<00:02, 11.6MB/s]\n",
            " 81%|████████  | 118M/147M [00:10<00:02, 11.6MB/s]\n",
            " 82%|████████▏ | 120M/147M [00:10<00:02, 11.6MB/s]\n",
            " 83%|████████▎ | 122M/147M [00:10<00:02, 11.6MB/s]\n",
            " 84%|████████▍ | 123M/147M [00:10<00:02, 11.5MB/s]\n",
            " 85%|████████▌ | 125M/147M [00:11<00:01, 11.5MB/s]\n",
            " 86%|████████▌ | 126M/147M [00:11<00:01, 11.5MB/s]\n",
            " 87%|████████▋ | 128M/147M [00:11<00:01, 11.5MB/s]\n",
            " 88%|████████▊ | 129M/147M [00:11<00:01, 11.5MB/s]\n",
            " 89%|████████▉ | 131M/147M [00:11<00:01, 11.6MB/s]\n",
            " 90%|█████████ | 133M/147M [00:11<00:01, 11.6MB/s]\n",
            " 91%|█████████▏| 134M/147M [00:11<00:01, 11.5MB/s]\n",
            " 93%|█████████▎| 136M/147M [00:11<00:00, 11.5MB/s]\n",
            " 94%|█████████▎| 137M/147M [00:12<00:00, 11.5MB/s]\n",
            " 95%|█████████▍| 139M/147M [00:12<00:00, 11.6MB/s]\n",
            " 96%|█████████▌| 141M/147M [00:12<00:00, 11.5MB/s]\n",
            " 97%|█████████▋| 142M/147M [00:12<00:00, 11.5MB/s]\n",
            " 98%|█████████▊| 144M/147M [00:12<00:00, 11.5MB/s]\n",
            " 99%|█████████▉| 145M/147M [00:12<00:00, 11.6MB/s]\n",
            "100%|██████████| 147M/147M [00:12<00:00, 11.6MB/s]\n",
            "100%|██████████| 147M/147M [00:12<00:00, 11.3MB/s]\n"
          ]
        }
      ],
      "source": [
        "# 171 grayscale - https://drive.google.com/file/d/16WD0td1f5gx4yIIDkWWSTb-oZcezI1CU/view?usp=drive_link\n",
        "!gdown 16WD0td1f5gx4yIIDkWWSTb-oZcezI1CU\n",
        "!tar -zxf AIA171_Miniset_BW.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1R3fxPknpDF6"
      },
      "outputs": [],
      "source": [
        "data_path = 'AIA171_Miniset_BW'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8T8W4jSpDF6"
      },
      "source": [
        "## Define 1D Power Spectrum and Wasserstein Distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_eYub1X-pDF7"
      },
      "outputs": [],
      "source": [
        "# Calculates 1d Power Spectrum\n",
        "def power_spectrum_1d(image):\n",
        "\n",
        "    # Get pixel count\n",
        "    pixel_count = image.shape[0]\n",
        "\n",
        "    # Convert into fourier transform\n",
        "    fourier_image = np.fft.fftn(image)\n",
        "    fourier_amplitudes = np.abs(fourier_image)\n",
        "\n",
        "    #Calculate 1D power spectrum\n",
        "    k_frequencies = np.fft.fftfreq(pixel_count) * pixel_count\n",
        "    k_frequencies2D = np.meshgrid(k_frequencies, k_frequencies)\n",
        "    k_norm = np.sqrt(k_frequencies2D[0] ** 2 + k_frequencies2D[1] ** 2)\n",
        "    k_bins = np.arange(0.5, pixel_count // 2 + 1, 1.)\n",
        "    k_vals = 0.5 * (k_bins[1:] + k_bins[:-1])\n",
        "    a_bins, _, _ = stats.binned_statistic(k_norm.flatten(),\n",
        "                                        (fourier_amplitudes ** 2).flatten(),\n",
        "                                        statistic = \"mean\", bins = k_bins)\n",
        "    a_bins *= np.pi * (k_bins[1:] ** 2 - k_bins[:-1] ** 2)\n",
        "\n",
        "    return a_bins\n",
        "\n",
        "# Calculates Wasserstein distance of two images\n",
        "def wasserstein(x, y):\n",
        "    return stats.wasserstein_distance(np.arange(len(x)), np.arange(len(y)), x, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeCqnG28pDF7"
      },
      "source": [
        "## Define Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXGTR2pNpDF7"
      },
      "outputs": [],
      "source": [
        "class PowerSpectrumDataset(Dataset):\n",
        "    def __init__(self, data_path, data_stride, datatype=np.float32):\n",
        "\n",
        "        self.data_path = data_path\n",
        "        self.image_files = glob.glob(data_path + \"/**/*.jpg\", recursive=True)\n",
        "        if data_stride > 1:\n",
        "            self.image_files = self.image_files[::data_stride]\n",
        "        self.datatype=datatype\n",
        "\n",
        "    def __len__(self):\n",
        "\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        image = read_image(image_loc = self.image_files[idx], image_format=\"jpg\")\n",
        "\n",
        "        power_spectrum = power_spectrum_1d(image)\n",
        "\n",
        "        if power_spectrum.any():\n",
        "            return image, power_spectrum, self.image_files[idx]\n",
        "        else:\n",
        "            return image, self.image_files[idx]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqKBVv8HpDF8"
      },
      "source": [
        "## Define BYOL Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEv9F8jtpDF8"
      },
      "outputs": [],
      "source": [
        "class BYOL(pl.LightningModule):\n",
        "    def __init__(self, lr=0.1, projection_size=256, prediction_size=256, cosine_scheduler_start=0.1, cosine_scheduler_end=1.0, epochs=10, loss='cos'):\n",
        "        super().__init__()\n",
        "\n",
        "        resnet = torchvision.models.resnet18() # Play w/ resnet.\n",
        "        self.backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
        "        self.projection_head = BYOLProjectionHead(512, 1024, projection_size)\n",
        "        self.prediction_head = BYOLPredictionHead(projection_size, 1024, prediction_size)\n",
        "\n",
        "        self.backbone_momentum = copy.deepcopy(self.backbone)\n",
        "        self.projection_head_momentum = copy.deepcopy(self.projection_head)\n",
        "\n",
        "        deactivate_requires_grad(self.backbone_momentum)\n",
        "        deactivate_requires_grad(self.projection_head_momentum)\n",
        "\n",
        "        self.loss = loss\n",
        "        self.loss_cos = NegativeCosineSimilarity()\n",
        "        self.loss_contrast = NTXentLoss()\n",
        "\n",
        "        self.cosine_scheduler_start = cosine_scheduler_start\n",
        "        self.cosine_scheduler_end = cosine_scheduler_end\n",
        "        self.epochs = epochs\n",
        "        self.lr = lr\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.backbone(x).flatten(start_dim=1)\n",
        "        z = self.projection_head(y)\n",
        "        p = self.prediction_head(z)\n",
        "        return p\n",
        "\n",
        "    def forward_momentum(self, x):\n",
        "        y = self.backbone_momentum(x).flatten(start_dim=1)\n",
        "        z = self.projection_head_momentum(y)\n",
        "        z = z.detach()\n",
        "        return z\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "\n",
        "        momentum = cosine_schedule(self.current_epoch, self.epochs, self.cosine_scheduler_start, self.cosine_scheduler_end)\n",
        "        update_momentum(self.backbone, self.backbone_momentum, m=momentum)\n",
        "        update_momentum(self.projection_head, self.projection_head_momentum, m=momentum)\n",
        "        (x0, x1, _) = batch\n",
        "        p0 = self.forward(x0)\n",
        "        z0 = self.forward_momentum(x0)\n",
        "        p1 = self.forward(x1)\n",
        "        z1 = self.forward_momentum(x1)\n",
        "\n",
        "        loss_cos = 0.5 * (self.loss_cos(p0, z1) + self.loss_cos(p1, z0))\n",
        "        loss_contrast = 0.5 * (self.loss_contrast(p0, z1) + self.loss_contrast(p1, z0))\n",
        "\n",
        "        if self.loss == 'cos':\n",
        "            loss = loss_cos\n",
        "        else:\n",
        "            loss = loss_contrast\n",
        "\n",
        "        self.log('loss cos', loss_cos)\n",
        "        self.log('loss contrast', loss_contrast)\n",
        "        self.log('loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.SGD(self.parameters(), lr=self.lr) # Play w/ optimizers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4pQh46SpDF9",
        "outputId": "a43a56c5-dd32-435d-9245-6ed977516657"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Seed set to 42\n"
          ]
        }
      ],
      "source": [
        "seed = 42\n",
        "pl.seed_everything(seed, workers=True)\n",
        "\n",
        "learning_rate = 0.1\n",
        "projection_size = 32\n",
        "prediction_size = 32\n",
        "cosine_scheduler_start = .1\n",
        "cosine_scheduler_end = 1.0\n",
        "epochs = 4\n",
        "data_stride = 1\n",
        "batch_size = 512\n",
        "loss = 'contrast'   # 'contrast' or 'cos'\n",
        "\n",
        "model = BYOL(lr=learning_rate,\n",
        "             projection_size=projection_size,\n",
        "             prediction_size=prediction_size,\n",
        "             cosine_scheduler_start=cosine_scheduler_start,\n",
        "             cosine_scheduler_end=cosine_scheduler_end,\n",
        "             epochs=epochs,\n",
        "             loss=loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULDrnNukpDF9"
      },
      "source": [
        "## Initialize Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Sq7EyGzpDF9"
      },
      "outputs": [],
      "source": [
        "dataset = PowerSpectrumDataset(data_path=data_path, data_stride=data_stride)\n",
        "\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    drop_last=False,\n",
        "    num_workers=8,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUakFFeJpDF9"
      },
      "source": [
        "## Run Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNHxjNoDpDF9",
        "outputId": "d5b5bdff-a439-4136-b13f-20615e6e90e1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "c:\\Users\\starf\\miniconda3\\envs\\sdo_research\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\logger_connector\\logger_connector.py:67: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
            "\n",
            "  | Name                     | Type                     | Params\n",
            "----------------------------------------------------------------------\n",
            "0 | backbone                 | Sequential               | 11.2 M\n",
            "1 | projection_head          | BYOLProjectionHead       | 559 K \n",
            "2 | prediction_head          | BYOLPredictionHead       | 67.6 K\n",
            "3 | backbone_momentum        | Sequential               | 11.2 M\n",
            "4 | projection_head_momentum | BYOLProjectionHead       | 559 K \n",
            "5 | loss_cos                 | NegativeCosineSimilarity | 0     \n",
            "6 | loss_contrast            | NTXentLoss               | 0     \n",
            "----------------------------------------------------------------------\n",
            "11.8 M    Trainable params\n",
            "11.7 M    Non-trainable params\n",
            "23.5 M    Total params\n",
            "94.156    Total estimated model params size (MB)\n",
            "c:\\Users\\starf\\miniconda3\\envs\\sdo_research\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:436: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
          ]
        }
      ],
      "source": [
        "trainer = pl.Trainer(max_epochs=epochs,\n",
        "                     accelerator=\"auto\", devices=\"auto\", strategy=\"auto\",\n",
        "                    log_every_n_steps=10, deterministic=True)\n",
        "\n",
        "trainer.fit(model=model, train_dataloaders=dataloader)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "sdo_research",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}